{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "# GPM: Generative Password Manager\n",
        "\n",
        "> Stateless password manager, powered by neural networks.\n",
        "\n",
        "Password management is up there with cookie popups and ads, a major pain in the ass.\n",
        "\n",
        "Turns out you don't need to *save* passwords, they can all be *derived* from a single master key.\n",
        "\n",
        "Here's a small experiment using neural networks."
      ],
      "metadata": {
        "id": "zMH2-aou0ig5"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Intuition\n",
        "\n",
        "Password managers can be seen as a deterministic function:\n",
        "given a target (app, website, etc) and a login ID (username, mail, etc) they produce a password.\n",
        "\n",
        "```python\n",
        "password = manager(target, login)\n",
        "```\n",
        "\n",
        "Typically they just save your credentials to ensure you always get the same password.\n",
        "\n",
        "Despite appearances, neural networks are actually deterministic too.\n",
        "So the `manager` function above could be a (L)LM.\n",
        "\n",
        "In this case:\n",
        "\n",
        "- the master key would be used to initiate the weights\n",
        "- the MLP would take the login and / or target as input prompt\n",
        "- the passwords would *not be saved* but generated as \"prediction\" of the model\n",
        "\n",
        "Also, the vocabulary and model can be setup to:\n",
        "\n",
        "- satisfy the password requirements\n",
        "- have high entropy while being deterministic\n",
        "- create memorable passwords like a sentence, contrary to random generation"
      ],
      "metadata": {
        "id": "6UAIlk6s-rxl"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Process Overview\n",
        "\n",
        "The user provides:\n",
        "\n",
        "- a master key\n",
        "- the login informations:\n",
        "    - target URL\n",
        "    - user ID (optional)\n",
        "\n",
        "And tweaks the default password properties:\n",
        "\n",
        "- its length\n",
        "- the composition of its vocabulary (upper / lower letters, numbers, symbols)\n",
        "- the nonce, to allow multiple passwords per website\n",
        "\n",
        "These inputs are then processed:\n",
        "\n",
        "0. setup the hyper-parameters:\n",
        "    - use the whole ASCII table as input vocabulary and save its shape\n",
        "    - compose the output vocabulary and save its shape\n",
        "    - cast the master key into an integer seed\n",
        "1. preprocess / clean the string inputs:\n",
        "    - remove unwanted characters\n",
        "    - normalize the strings\n",
        "2. encode the inputs as a sequence tensor X for the MLP:\n",
        "    - map the input characters to integers\n",
        "    - add entropy to avoid repetitions in the output\n",
        "    - format as a tensor\n",
        "3. create the model corresponding to the hyper-parameters\n",
        "4. sample / generate the password as a tensor Y\n",
        "5. decode the probability tensor Y into an actual password string"
      ],
      "metadata": {
        "id": "OmjJPYyxW1xn"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Import Dependencies"
      ],
      "metadata": {
        "id": "H6bxcgIcYEXk"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import argparse\n",
        "import datetime\n",
        "import functools\n",
        "import hashlib\n",
        "import itertools\n",
        "import math\n",
        "import os\n",
        "import random\n",
        "import re\n",
        "\n",
        "import tensorflow as tf"
      ],
      "metadata": {
        "id": "ad6y4gY-X03N"
      },
      "execution_count": 1,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 0. Setup The Hyper Parameters\n",
        "\n",
        "The generative function is a MLP: it is defined by hyper-parameters.\n",
        "\n",
        "- the seed for the random number generators\n",
        "- the tensor shapes\n",
        "- the input vocabulary (all the ASCII characters)\n",
        "- the output vocabulary (alpha / numbers / symbols)\n",
        "- the password length, which is the length of the sampling"
      ],
      "metadata": {
        "id": "ZuMSNLoXYTDm"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### 0.1. Defining the Input Vocabulary\n",
        "\n",
        "The inputs are projected on the ASCII table, all unicode characters are ignored.\n",
        "\n",
        "This vocabulary is fixed, whatever the user typed:"
      ],
      "metadata": {
        "id": "jj0bnnz0YYAQ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# DEFAULT INPUT VOCABULARY ####################################################\n",
        "\n",
        "INPUT_VOCABULARY = ''.join(chr(__i) for __i in range(128)) # all ASCII characters"
      ],
      "metadata": {
        "id": "1YEDdQrGYZOY"
      },
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### 0.2. Composing The Output Vocabulary\n",
        "\n",
        "The output vocabulary dictates the composition of the model output, IE the password.\n",
        "\n",
        "This vocabulary can contain:\n",
        "\n",
        "- lowercase letters\n",
        "- uppercase letters\n",
        "- digits\n",
        "- ASCII symbols, apart from the quotes `\"` and `'`"
      ],
      "metadata": {
        "id": "nP1IPzZ2crP2"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# DEFAULT OUTPUT VOCABULARY ###################################################\n",
        "\n",
        "VOCABULARY_ALPHA_UPPER = ''.join(chr(__i) for __i in range(65, 91))                             # A-Z\n",
        "VOCABULARY_ALPHA_LOWER = VOCABULARY_ALPHA_UPPER.lower()                                         # a-z\n",
        "VOCABULARY_NUMBERS = '0123456789'                                                               # 0-9\n",
        "VOCABULARY_SYMBOLS = ''.join(chr(__i) for __i in range(33, 48) if chr(__i) not in [\"'\", '\"'])   # !#$%&\\()*+,-./\n",
        "\n",
        "OUTPUT_VOCABULARY = INPUT_VOCABULARY # placeholder"
      ],
      "metadata": {
        "id": "W23WeK8TczJs"
      },
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "It is generated from the user preferences with:"
      ],
      "metadata": {
        "id": "FwaYgg7Nc-Q8"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# VOCABULARY ##################################################################\n",
        "\n",
        "def compose(lower: bool=True, upper: bool=True, digits: bool=True, symbols: bool=False) -> str:\n",
        "    return sorted(set(lower * VOCABULARY_ALPHA_LOWER + upper * VOCABULARY_ALPHA_UPPER + digits * VOCABULARY_NUMBERS + symbols * VOCABULARY_SYMBOLS))"
      ],
      "metadata": {
        "id": "Zeibhevrc_gU"
      },
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "By default, it is:"
      ],
      "metadata": {
        "id": "uXCs9USldFj-"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "''.join(compose(1, 1, 1, 0))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "id": "X1ZK3cxBdO0j",
        "outputId": "38f16f66-8681-4962-f43a-60380898a2a4"
      },
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'0123456789ABCDEFGHIJKLMNOPQRSTUVWXYZabcdefghijklmnopqrstuvwxyz'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 5
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "In the end, the meta-parameters are:"
      ],
      "metadata": {
        "id": "VLHgSreDdRn9"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# DEFAULT META ################################################################\n",
        "\n",
        "N_INPUT_DIM = len(INPUT_VOCABULARY) # all ASCII characters\n",
        "N_OUTPUT_DIM = N_INPUT_DIM # placeholder, it depends on the user settings\n",
        "\n",
        "N_CONTEXT_DIM = 8\n",
        "N_EMBEDDING_DIM = 128\n",
        "\n",
        "N_PASSWORD_DIM = 16\n",
        "N_PASSWORD_NONCE = 1"
      ],
      "metadata": {
        "id": "OlzgfasndWXH"
      },
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### 0.3. Casting The Master Key Into The Seed\n",
        "\n",
        "A naive approach is to interpret the master key as a HEX sequence, then cast into the integer seed:"
      ],
      "metadata": {
        "id": "TDNcx_VPdbIG"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def seed(key: str) -> int:\n",
        "    return int(bytes(key, 'utf-8').hex(), 16) % (2 ** 32) # dword"
      ],
      "metadata": {
        "id": "W-jXNdbFdbu4"
      },
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "But many inputs produce the same seed:"
      ],
      "metadata": {
        "id": "f5Aqj2VWeHSW"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "print(seed('never seen before combination of letters'))\n",
        "print(seed('combination of letters'))\n",
        "print(b'combination of letters'.hex())"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "M4sM-0a8dpIJ",
        "outputId": "f913275c-7ccd-4507-eb3c-f5d407407e44"
      },
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "3588870616\n",
            "3269272188\n",
            "636f6d62696e6174696f6e206f66206c657474657273\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "The encoding of the string 'combination of letters' requires 22 bytes, so it is greater than 2 ** 168. Prepending a prefix means adding a number times 2 ** 176 which leads to the same value modulo 2 ** 32.\n",
        "\n",
        "To separate the encoding of similar mater keys, it is first hashed using sha256:"
      ],
      "metadata": {
        "id": "_nHBhhUjeGhB"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def seed(key: str) -> int:\n",
        "    __hash = hashlib.sha256(string=key.encode('utf-8')).hexdigest()\n",
        "    return int(__hash[:8], 16) # take the first 4 bytes: the seed is lower than 2 ** 32"
      ],
      "metadata": {
        "id": "lGW4Q7ALeWV1"
      },
      "execution_count": 12,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Now:"
      ],
      "metadata": {
        "id": "SBlH1uCFfG3_"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "print(seed('never seen before combination of letters'))\n",
        "print(seed('combination of letters'))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "yZNA-P_UfJqB",
        "outputId": "2e61b695-2630-42f6-a10f-7aa285236445"
      },
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "3588870616\n",
            "3269272188\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 1. Preprocessing The Inputs\n",
        "\n",
        "The inputs are the login information for which the user wants a password:\n",
        "\n",
        "- login target\n",
        "- login id\n",
        "\n",
        "Before being handled to the model, they need to be preprocessed to guarantee that the output matches the user expectations."
      ],
      "metadata": {
        "id": "nd57TTaefXb9"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### 1.1. Removing Unwanted Characters\n",
        "\n",
        "First, the inputs should be cleaned to:\n",
        "\n",
        "- remove spaces: they serve no purpose and are typos like `http://example. com`\n",
        "- remove unicode characters: many typos produce invisible control characters like `chr(2002)`\n",
        "\n",
        "Spaces can be removed with:"
      ],
      "metadata": {
        "id": "Z8jxar-efYFE"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def remove_spaces(text: str) -> str:\n",
        "    return text.replace(' ', '').replace('\\t', '')"
      ],
      "metadata": {
        "id": "aVDjvCUFfb-x"
      },
      "execution_count": 14,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### 1.2. Normalizing The Strings\n",
        "\n",
        "Several variants can be used to point to the same service:\n",
        "\n",
        "```\n",
        "example.com\n",
        "https://example.com\n",
        "https://example.com/\n",
        "ExamPLE.COM\n",
        "```\n",
        "\n",
        "So they need to be normalized with:"
      ],
      "metadata": {
        "id": "cRBiZZMJfoGX"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def remove_prefix(text: str) -> str:\n",
        "    __r = r'^((?:ftp|https?):\\/\\/)'\n",
        "    return re.sub(pattern=__r, repl='', string=text, flags=re.IGNORECASE)\n",
        "\n",
        "def remove_suffix(text: str) -> str:\n",
        "    __r = r'(\\/+)$'\n",
        "    return re.sub(pattern=__r, repl='', string=text, flags=re.IGNORECASE)"
      ],
      "metadata": {
        "id": "c46pMdzJftmB"
      },
      "execution_count": 15,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "\n",
        "Pieced together:"
      ],
      "metadata": {
        "id": "hqIsnm8wfxem"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def preprocess(target: str, login: str) -> list:\n",
        "    __left = remove_suffix(text=remove_prefix(text=remove_spaces(text=target.lower())))\n",
        "    __right = remove_spaces(text=login.lower())\n",
        "    return __left + '|' + __right"
      ],
      "metadata": {
        "id": "AT0aQV8MfzCF"
      },
      "execution_count": 16,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(preprocess(target='example.com', login='user'))\n",
        "print(preprocess(target='https://example.com', login='user'))\n",
        "print(preprocess(target='example.com/', login='USER'))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "IUMp5Uy8gAoL",
        "outputId": "61560c8d-1be8-4ccf-eea1-feabbf5778cf"
      },
      "execution_count": 17,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "example.com|user\n",
            "example.com|user\n",
            "example.com|user\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 2. Encoding The Inputs\n",
        "\n",
        "### 2.1. Mapping The Characters To Integers\n",
        "\n",
        "The mapping between character and integer is a straightforward enumeration:"
      ],
      "metadata": {
        "id": "6IaQqpJvgLAt"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def mappings(vocabulary: list) -> dict:\n",
        "    __itos = {__i: __c for __i, __c in enumerate(vocabulary)}\n",
        "    __stoi = {__c: __i for __i, __c in enumerate(vocabulary)}\n",
        "    # blank placeholder\n",
        "    __blank_c = __itos[0] # chr(0)\n",
        "    __blank_i = 0\n",
        "    # s => i\n",
        "    def __encode(c: str) -> int:\n",
        "        return __stoi.get(c, __blank_i)\n",
        "    # i => s\n",
        "    def __decode(i: int) -> str:\n",
        "        return __itos.get(i, __blank_c)\n",
        "    # return both\n",
        "    return {'encode': __encode, 'decode': __decode}"
      ],
      "metadata": {
        "id": "Gx0STESAgLhM"
      },
      "execution_count": 18,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "It will remove all the characters outside the input vocabulary, EG unicode characters."
      ],
      "metadata": {
        "id": "-tuwxti4gObe"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def encode(text: str, stoi: callable) -> list:\n",
        "    return [stoi(__c) for __c in text] # defaults to 0 if a character is not in the vocabulary\n",
        "\n",
        "def decode(sequence: list, itos: callable) -> list:\n",
        "    return ''.join([itos(__i) for __i in sequence]) # defaults to the first character"
      ],
      "metadata": {
        "id": "H3vvpscDgQ5E"
      },
      "execution_count": 19,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### 2.2. Adding Entropy\n",
        "\n",
        "With a character level embedding the input tensor would look like:\n",
        "\n",
        "```python\n",
        "array([101, 120,  97, 109, 112, 108, 101,  46,  99, 111, 109, 124, 117, 115, 101, 114], dtype=int32)\n",
        "```\n",
        "\n",
        "Which means that *each repetition in the input would also yield a repetition in the output password*.\n",
        "\n",
        "Just like regular transformer models, using a context as input will make each sample more unique.\n",
        "Instead of a single character, a sample is now composed of the N latest characters:\n",
        "\n",
        "```python\n",
        "array([[  0,   0,   0,   0,   0,   0,   0,   0],\n",
        "       [  0,   0,   0,   0,   0,   0,   0, 101],\n",
        "       [  0,   0,   0,   0,   0,   0, 101, 120],\n",
        "       [  0,   0,   0,   0,   0, 101, 120,  97],\n",
        "       [  0,   0,   0,   0, 101, 120,  97, 109],\n",
        "       [  0,   0,   0, 101, 120,  97, 109, 112],\n",
        "       [  0,   0, 101, 120,  97, 109, 112, 108],\n",
        "       [  0, 101, 120,  97, 109, 112, 108, 101],\n",
        "       [101, 120,  97, 109, 112, 108, 101,  46],\n",
        "       [120,  97, 109, 112, 108, 101,  46,  99],\n",
        "       [ 97, 109, 112, 108, 101,  46,  99, 111],\n",
        "       [109, 112, 108, 101,  46,  99, 111, 109],\n",
        "       [112, 108, 101,  46,  99, 111, 109, 124],\n",
        "       [108, 101,  46,  99, 111, 109, 124, 117],\n",
        "       [101,  46,  99, 111, 109, 124, 117, 115],\n",
        "       [ 46,  99, 111, 109, 124, 117, 115, 101]], dtype=int32)\n",
        "```\n",
        "\n",
        "This can still be improved.\n",
        "As long as the process is deterministic, the input can be modified in any way.\n",
        "\n",
        "For example, the successive ordinal values can be accumulated:"
      ],
      "metadata": {
        "id": "_hbTCKBdga-u"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def accumulate(x: int, y: int, n: int) -> int:\n",
        "    return (x + y) % n"
      ],
      "metadata": {
        "id": "_UaIJaoRgdQ4"
      },
      "execution_count": 20,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "The modulo guarantees that the encoding stays within the range of the ASCII encoding.\n",
        "\n",
        "Also the context can start from the current index, instead of ending on it. Finally the encoded input can be cycled through to create and infinite iterator:"
      ],
      "metadata": {
        "id": "OCJtz5JEgfnC"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def feed(source: list, nonce: int, dimension: int) -> iter:\n",
        "    __func = lambda __x, __y: accumulate(x=__x, y=__y + nonce, n=dimension) # add entropy by accumulating the encodings\n",
        "    return itertools.accumulate(iterable=itertools.cycle(source), func=__func) # infinite iterable"
      ],
      "metadata": {
        "id": "XayVwmLWgiX7"
      },
      "execution_count": 21,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "This will allow to create passwords longer than the input text."
      ],
      "metadata": {
        "id": "eWNqW26NgnQt"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### 2.3. Formatting As A Tensor\n",
        "\n",
        "Finally, the iterator of encoded inputs is used to generate the tensor X:"
      ],
      "metadata": {
        "id": "KnPVw-4ygnyF"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def tensor(feed: 'Iterable[int]', length: int, context: int) -> tf.Tensor:\n",
        "    __x = [[next(feed) for _ in range(context)] for _ in range(length)]\n",
        "    return tf.constant(tf.convert_to_tensor(value=__x, dtype=tf.dtypes.int32))"
      ],
      "metadata": {
        "id": "7pgPcdl1g0_0"
      },
      "execution_count": 22,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "This tensor has shape (N_PASSWORD_LENGTH, N_CONTEXT_DIM):"
      ],
      "metadata": {
        "id": "funRKwJSg5f-"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "__feed = feed(source=list('kaggle.com|apehex'.encode('utf-8')), nonce=1, dimension=256)\n",
        "tensor(feed=__feed, length=N_PASSWORD_DIM, context=N_CONTEXT_DIM)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "sEFSf1BMg6Gp",
        "outputId": "79ea11cd-16fa-4642-b831-179cba878afe"
      },
      "execution_count": 23,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<tf.Tensor: shape=(16, 8), dtype=int32, numpy=\n",
              "array([[107, 205,  53, 157,  10, 112, 159,   3],\n",
              "       [115, 225,  94, 192,  49, 151,   0, 102],\n",
              "       [223,  75, 173,  21, 125, 234,  80, 127],\n",
              "       [227,  83, 193,  62, 160,  17, 119, 224],\n",
              "       [ 70, 191,  43, 141, 245,  93, 202,  48],\n",
              "       [ 95, 195,  51, 161,  30, 128, 241,  87],\n",
              "       [192,  38, 159,  11, 109, 213,  61, 170],\n",
              "       [ 16,  63, 163,  19, 129, 254,  96, 209],\n",
              "       [ 55, 160,   6, 127, 235,  77, 181,  29],\n",
              "       [138, 240,  31, 131, 243,  97, 222,  64],\n",
              "       [177,  23, 128, 230,  95, 203,  45, 149],\n",
              "       [253, 106, 208, 255,  99, 211,  65, 190],\n",
              "       [ 32, 145, 247,  96, 198,  63, 171,  13],\n",
              "       [117, 221,  74, 176, 223,  67, 179,  33],\n",
              "       [158,   0, 113, 215,  64, 166,  31, 139],\n",
              "       [237,  85, 189,  42, 144, 191,  35, 147]], dtype=int32)>"
            ]
          },
          "metadata": {},
          "execution_count": 23
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "\n",
        "Even though the input strings 'kaggle.com|apehex' had repetitions (\"e\" and \"a\") no two lines of the tensor are the same.\n",
        "\n",
        "The process detailed here will always produce the same tensor X."
      ],
      "metadata": {
        "id": "aUhOEe-_g-fz"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 3. Creating The MLP Model\n",
        "\n",
        "Now that all the hyper-parameters are set, creating the MLP is just a formality:"
      ],
      "metadata": {
        "id": "Plo3JZ5HhKI1"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# MODEL #######################################################################\n",
        "\n",
        "def create_model(\n",
        "    seed: int,\n",
        "    n_input_dim: int,\n",
        "    n_output_dim: int,\n",
        "    n_context_dim: int=N_CONTEXT_DIM,\n",
        "    n_embedding_dim: int=N_EMBEDDING_DIM,\n",
        ") -> tf.keras.Model:\n",
        "    __model = tf.keras.Sequential()\n",
        "    # initialize the weights\n",
        "    __embedding_init = tf.keras.initializers.GlorotNormal(seed=seed)\n",
        "    __dense_init = tf.keras.initializers.GlorotNormal(seed=(seed ** 2) % (2 ** 32)) # different values\n",
        "    # embedding\n",
        "    __model.add(tf.keras.layers.Embedding(input_dim=n_input_dim, output_dim=n_embedding_dim, embeddings_initializer=__embedding_init, name='embedding'))\n",
        "    # head\n",
        "    __model.add(tf.keras.layers.Reshape(target_shape=(n_context_dim * n_embedding_dim,), input_shape=(n_context_dim, n_embedding_dim), name='reshape'))\n",
        "    __model.add(tf.keras.layers.Dense(units=n_output_dim, activation='tanh', use_bias=False, kernel_initializer=__dense_init, name='head'))\n",
        "    __model.add(tf.keras.layers.Softmax(axis=-1, name='softmax'))\n",
        "    # compile\n",
        "    __model.compile(\n",
        "        optimizer=tf.keras.optimizers.Adam(learning_rate=0.0001),\n",
        "        loss=tf.keras.losses.CategoricalCrossentropy(from_logits=False, label_smoothing=0., axis=-1, reduction=tf.keras.losses.Reduction.SUM_OVER_BATCH_SIZE, name='loss'))\n",
        "    return __model"
      ],
      "metadata": {
        "id": "6UJa_8GMhNry"
      },
      "execution_count": 24,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "For the purpose of this POC we are using Tensorflow and Keras, but it could actually be done with basic matrix multiplications.\n",
        "\n",
        "Numpy would be almost as convenient to use and yield the same result."
      ],
      "metadata": {
        "id": "NvdCvRyKhriS"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 4. Sampling = Password Generation\n",
        "\n",
        "The forward pass of the tensor X in the above model will result in the probabilities for each character in the output vocabulary.\n",
        "\n",
        "This can be directly decoded as a string like this:"
      ],
      "metadata": {
        "id": "QsOidQwahsDs"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def password(model: tf.keras.Model, x: tf.Tensor, itos: callable) -> str:\n",
        "    __y = tf.squeeze(model(x, training=False))\n",
        "    __p = list(tf.argmax(__y, axis=-1).numpy())\n",
        "    return decode(__p, itos=itos)"
      ],
      "metadata": {
        "id": "iS2A6vFkhu1m"
      },
      "execution_count": 25,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Evaluation\n",
        "\n",
        "All the operations are pieced together in the `process` function:"
      ],
      "metadata": {
        "id": "0fDL3NhJh4wE"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def process(\n",
        "    master_key: str,\n",
        "    login_target: str,\n",
        "    login_id: str,\n",
        "    password_length: int,\n",
        "    password_nonce: int,\n",
        "    include_lower: bool,\n",
        "    include_upper: bool,\n",
        "    include_digits: bool,\n",
        "    include_symbols: bool,\n",
        "    input_vocabulary: str=INPUT_VOCABULARY,\n",
        "    model_context_dim: int=N_CONTEXT_DIM,\n",
        "    model_embedding_dim: int=N_EMBEDDING_DIM\n",
        ") -> str:\n",
        "    # seed to generate the model weights randomly\n",
        "    __seed = seed(key=master_key)\n",
        "    # input vocabulary\n",
        "    __input_mappings = mappings(vocabulary=input_vocabulary)\n",
        "    __input_dim = len(input_vocabulary)\n",
        "    # output vocabulary\n",
        "    __output_vocabulary = compose(lower=include_lower, upper=include_upper, digits=include_digits, symbols=include_symbols)\n",
        "    __output_mappings = mappings(vocabulary=__output_vocabulary)\n",
        "    __output_dim = len(__output_vocabulary)\n",
        "    # inputs\n",
        "    __inputs = preprocess(target=login_target, login=login_id)\n",
        "    __source = encode(text=__inputs, stoi=__input_mappings['encode'])\n",
        "    __feed = feed(source=__source, nonce=password_nonce, dimension=__input_dim)\n",
        "    __x = tensor(feed=__feed, length=password_length, context=model_context_dim)\n",
        "    # model\n",
        "    __model = create_model(seed=__seed, n_input_dim=__input_dim, n_output_dim=__output_dim, n_context_dim=model_context_dim, n_embedding_dim=model_embedding_dim)\n",
        "    # password\n",
        "    return password(model=__model, x=__x, itos=__output_mappings['decode'])"
      ],
      "metadata": {
        "id": "aaHWp09Xh6dG"
      },
      "execution_count": 26,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "\n",
        "We can fix the internal parameters of the model like so:"
      ],
      "metadata": {
        "id": "Gp-LDm9GiLGe"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "_process = functools.partial(\n",
        "    process,\n",
        "    password_length=32,\n",
        "    password_nonce=1,\n",
        "    include_lower=True,\n",
        "    include_upper=True,\n",
        "    include_digits=True,\n",
        "    include_symbols=False,\n",
        "    input_vocabulary=INPUT_VOCABULARY,\n",
        "    model_context_dim=N_CONTEXT_DIM,\n",
        "    model_embedding_dim=N_EMBEDDING_DIM)"
      ],
      "metadata": {
        "id": "DKNGnQwxiLl7"
      },
      "execution_count": 27,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Which makes it easier to test the password generation:"
      ],
      "metadata": {
        "id": "QbOKOe4ciNu4"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "print(_process(master_key='test', login_target='huggingface.co', login_id='apehex'))\n",
        "print(_process(master_key='test', login_target='https://huggingface.co/', login_id='APEHEX'))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "_VX8vVwNiPlz",
        "outputId": "08bf1ba6-ce34-4118-e721-c7df4914656a"
      },
      "execution_count": 28,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "UEkmcY3IgIjT7o0ISs7qNon66FIVT1Qi\n",
            "UEkmcY3IgIjT7o0ISs7qNon66FIVT1Qi\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "\n",
        "As expected the whole process is deterministic: calls with equivalent inputs will always yield the same password, there is no need to save it."
      ],
      "metadata": {
        "id": "fzb9lCSqil5Z"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "print(_process(master_key='verysecretpassphrase', login_target='example.com', login_id='u s e r@EMAIL.COM'))\n",
        "print(_process(master_key='verysecretpassphrase', login_target='HTTPS://example.com/', login_id='user@email.com'))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "4CMQWhwriq-j",
        "outputId": "a64aa179-8ae4-4fb7-c51f-3fcc4c701c25"
      },
      "execution_count": 29,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "4ZUHYALvuXvcSoS1p9j7R64freclXKvf\n",
            "4ZUHYALvuXvcSoS1p9j7R64freclXKvf\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## CLI\n",
        "\n",
        "I wrapped this script in a [Python CLI](https://github.com/apehex/gpm).\n",
        "\n",
        "```shell\n",
        "python  gpm/main.py --key 'never seen before combination of letters' --target 'http://example.com' --id 'user@e.mail'\n",
        "# YRLabEDKqWQrN6JF\n",
        "```\n",
        "\n",
        "- the master key\n",
        "- the login target\n",
        "- the login id\n",
        "\n",
        "If they are not specified on the command line, the user will be prompted during the execution:\n",
        "\n",
        "```shell\n",
        "python  gpm/main.py\n",
        "# > Master key:\n",
        "# never seen before combination of letters\n",
        "# > Login target:\n",
        "# http://example.com\n",
        "# > Login id:\n",
        "# user@mail.com\n",
        "```\n",
        "\n",
        "The full list of parameters is the following:\n",
        "\n",
        "```shell\n",
        "Generate / retrieve the password matching the input information\n",
        "\n",
        "optional arguments:\n",
        "  -h, --help                                    show this help message and exit\n",
        "  --key MASTER_KEY, -k MASTER_KEY               the master key (all ASCII)\n",
        "  --target LOGIN_TARGET, -t LOGIN_TARGET        the login target (URL, IP, name, etc)\n",
        "  --id LOGIN_ID, -i LOGIN_ID                    the login id (username, email, etc)\n",
        "  --length PASSWORD_LENGTH, -l PASSWORD_LENGTH  the length of the password (default 16)\n",
        "  --nonce PASSWORD_NONCE, -n PASSWORD_NONCE     the nonce of the password\n",
        "  --lower, -a                                   exclude lowercase letters from the password\n",
        "  --upper, -A                                   exclude uppercase letters from the password\n",
        "  --digits, -d                                  exclude digits from the password\n",
        "  --symbols, -s                                 include symbols in the password\n",
        "```"
      ],
      "metadata": {
        "id": "_d_z_bAdOjTp"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Improvements\n",
        "\n",
        "This POC could be turned into a full-fledged product with:\n",
        "\n",
        "- performance improvements:\n",
        "    - use the base `numpy` instead of `tensorflow`\n",
        "    - replace the model with its base weight tensors and matrix multiplications\n",
        "- more output options:\n",
        "    - generate the password as a bag of words\n",
        "    - create whole sentences / quotes\n",
        "    - force the use of certain characters / sub-vocabularies (like the symbols)\n",
        "- an actual distribution as:\n",
        "    - browser extension\n",
        "    - binary executable (CLI)\n",
        "    - mobile app"
      ],
      "metadata": {
        "id": "9WbvYNXHiwx6"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "q3uuiLxjz9ch"
      },
      "outputs": [],
      "source": []
    }
  ]
}